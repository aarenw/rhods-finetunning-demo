{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797f3d2c-0aea-4dbd-880c-9d0657c8e85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/caikit/caikit-nlp.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130f5630-fb45-4351-9d5f-359667cb47f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/opendatahub-io/caikit-tgis-serving.git\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6500fde-8d50-4608-b794-8644facf29f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp caikit-tgis-serving/utils/convert.py . \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2553340c-1d04-4428-8f98-10b9f84f526b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: huggingface_hub in /opt/app-root/lib/python3.9/site-packages (0.18.0)\n",
      "Requirement already satisfied: requests in /opt/app-root/lib/python3.9/site-packages (from huggingface_hub) (2.31.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/app-root/lib/python3.9/site-packages (from huggingface_hub) (6.0)\n",
      "Requirement already satisfied: filelock in /opt/app-root/lib/python3.9/site-packages (from huggingface_hub) (3.8.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/app-root/lib/python3.9/site-packages (from huggingface_hub) (21.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/app-root/lib/python3.9/site-packages (from huggingface_hub) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/app-root/lib/python3.9/site-packages (from huggingface_hub) (4.8.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/app-root/lib/python3.9/site-packages (from huggingface_hub) (4.66.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/app-root/lib/python3.9/site-packages (from packaging>=20.9->huggingface_hub) (3.0.9)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/app-root/lib/python3.9/site-packages (from requests->huggingface_hub) (2.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/app-root/lib/python3.9/site-packages (from requests->huggingface_hub) (2022.9.24)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/app-root/lib/python3.9/site-packages (from requests->huggingface_hub) (1.26.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/app-root/lib/python3.9/site-packages (from requests->huggingface_hub) (3.4)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: write).\n",
      "Your token has been saved to /opt/app-root/src/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade huggingface_hub\n",
    "\n",
    "from huggingface_hub import login\n",
    "# Note: Prefer notebook_login() but this was not prompting properly\n",
    "login(token='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')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c64186-e364-4a07-9cd9-1032cdead96b",
   "metadata": {},
   "source": [
    "# Download through git , if git doesn't work, download is using transformat load then save it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d55e0a-71d0-4150-87d9-e2381a59d336",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git lfs install\n",
    "!git clone https://huggingface.co/Aareonwong/Llama-2-7b-chat-hf-fine-tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "80fad78e-a1c3-4422-a62a-9fdb61dbf8d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10aa49fc9b4d487bb526c384ff8b06f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)tuned/resolve/main/tokenizer_config.json:   0%|          | 0.00/1.71k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ca9311b5912494fb3b27c64bdb00b84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)f-fine-tuned/resolve/main/tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "893378c86db4412ea722e06df45d1322",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)ned/resolve/main/special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cfa4854fbdf4d41a14bb1daf04f53f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "model_id = \"Aareonwong/Llama-2-7b-chat-hf-fine-tuned\" \n",
    "\n",
    "\n",
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, cache_dir='./Llama-2-7b-chat-hf-fine-tuned')\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, cache_dir='./Llama-2-7b-chat-hf-fine-tuned')\n",
    "\n",
    "tokenizer.save_pretrained('./Llama-ft')\n",
    "model.save_pretrained('./Llama-ft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "832ed365-80a9-4a72-94cb-308d38c73c27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./Llama-ft/tokenizer_config.json',\n",
       " './Llama-ft/special_tokens_map.json',\n",
       " './Llama-ft/tokenizer.json')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.save_pretrained('./Llama-ft')\n",
    "model.save_pretrained('./Llama-ft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3e4d5cf2-22fd-422e-845f-7014b4a7ace9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function register_backend_type at 0x7ff063322ca0> is still in the BETA phase and subject to change!\n",
      "Loading checkpoint shards: 100%|██████████████████| 6/6 [01:21<00:00, 13.62s/it]\n"
     ]
    }
   ],
   "source": [
    "!./convert.py --model-path ./Llama-ft --model-save-path ./Llama-2-7b-chat-hf-fine-tuned-caikit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d998e41e-9b06-43f5-b7a0-532b1b21cf2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: grpcio in /opt/app-root/lib/python3.9/site-packages (1.59.2)\n",
      "Collecting grpcio-tools\n",
      "  Downloading grpcio_tools-1.59.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: setuptools in /opt/app-root/lib/python3.9/site-packages (from grpcio-tools) (67.3.1)\n",
      "Requirement already satisfied: protobuf<5.0dev,>=4.21.6 in /opt/app-root/lib/python3.9/site-packages (from grpcio-tools) (4.25.0)\n",
      "Installing collected packages: grpcio-tools\n",
      "Successfully installed grpcio-tools-1.59.2\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install grpcio grpcio-tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c982810c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-11-05 10:53:36--  https://github.com/fullstorydev/grpcurl/releases/download/v1.8.8/grpcurl_1.8.8_linux_x86_64.tar.gz\n",
      "Resolving github.com (github.com)... 20.205.243.166\n",
      "Connecting to github.com (github.com)|20.205.243.166|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/111431261/a47e3c29-44f2-426d-aa5d-ac64ff906faf?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20231105%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20231105T105336Z&X-Amz-Expires=300&X-Amz-Signature=214edb38d0894e645df442d2229ff96d6541a2f4443778a1156831f6c46f3982&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=111431261&response-content-disposition=attachment%3B%20filename%3Dgrpcurl_1.8.8_linux_x86_64.tar.gz&response-content-type=application%2Foctet-stream [following]\n",
      "--2023-11-05 10:53:36--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/111431261/a47e3c29-44f2-426d-aa5d-ac64ff906faf?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20231105%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20231105T105336Z&X-Amz-Expires=300&X-Amz-Signature=214edb38d0894e645df442d2229ff96d6541a2f4443778a1156831f6c46f3982&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=111431261&response-content-disposition=attachment%3B%20filename%3Dgrpcurl_1.8.8_linux_x86_64.tar.gz&response-content-type=application%2Foctet-stream\n",
      "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
      "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 7744368 (7.4M) [application/octet-stream]\n",
      "Saving to: ‘grpcurl_1.8.8_linux_x86_64.tar.gz’\n",
      "\n",
      "grpcurl_1.8.8_linux 100%[===================>]   7.38M  32.3MB/s    in 0.2s    \n",
      "\n",
      "2023-11-05 10:53:37 (32.3 MB/s) - ‘grpcurl_1.8.8_linux_x86_64.tar.gz’ saved [7744368/7744368]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/fullstorydev/grpcurl/releases/download/v1.8.8/grpcurl_1.8.8_linux_x86_64.tar.gz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6803c303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LICENSE\n",
      "grpcurl\n"
     ]
    }
   ],
   "source": [
    "!tar -xvzf grpcurl_1.8.8_linux_x86_64.tar.gz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "64d5397c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/bin/sh: line 1: grpcurl: command not found\n"
     ]
    }
   ],
   "source": [
    "!./grpcurl -insecure -d '{\"text\": \"How to please Demo Gods before the Demo?\", \"max_new_tokens\": 1024}' -H \"mm-model-id: Llama-2-7b-chat-hf-fine-tuned-caikit\" caikit-example-isvc-predictor-kserve-demo.appsocp03.anpslab.com:443 caikit.runtime.Nlp.NlpService/TextGenerationTaskPredict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c392167-61ba-4756-b108-0096eea171d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
